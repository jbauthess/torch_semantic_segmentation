{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo : using UNET to detect random squares in images\n",
    "\n",
    "In this notebook, **we're going to build a simple UNET model** to detect squares with random color at random location in a black image.\n",
    "It is a binary segmentation problem where pixels can only belong / not belong to a square.\n",
    "\n",
    "Data are generated through a custom synthetic Dataset providing images of squares and associated masks. We then:\n",
    "\n",
    "* `train the model` - fit the model on images of squares\n",
    "* `test and evaluate` - test model prediction and compute sgmentation scores\n",
    "\n",
    "The task at hand beeing simple, no data augmentation is used.\n",
    "\n",
    "This simple use case can be modified to check quickly the implementation of a custom model architecture.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "\n",
    "from src.model.unet import UNetModel\n",
    "from src.dataset.square_dataset import SquareDataset\n",
    "from src.benchmark.train import train, HyperParameters, EarlyStoppingParams, TrainParameters\n",
    "\n",
    "# algorithm hyperparameters\n",
    "# -------------------------\n",
    "NB_EPOCHS = 40\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "# model hyperparameters\n",
    "# ---------------------\n",
    "# for the simple task at hand the base number (12) used to compute the number of feature maps\n",
    "# in each model layer can be low. In the original paper this value is 64\n",
    "BASE_FM_NUMBER = 12  \n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_NB_CHANNELS = 3 # RGB images\n",
    "NB_LABELS = 1       # only one foreground class, remaining pixels beeing background \n",
    "INIT_WEIGHTS_PATH = None\n",
    "\n",
    "MODEL_PATH = \"./square_model_dict.pth\"\n",
    "\n",
    "logging.basicConfig(filename=None, filemode=\"w\", level=logging.DEBUG)\n",
    "\n",
    "# select device for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Selected device : {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train the model on a synthetic dataset composed of squares with different colors (1-label problem) \"\"\"\n",
    "\n",
    "# build model architecture\n",
    "model = UNetModel(IMG_NB_CHANNELS, NB_LABELS, BASE_FM_NUMBER)\n",
    "\n",
    "# create train and validation datasets of 100 images each\n",
    "nb_images = 100\n",
    "train_dataset = SquareDataset(IMG_NB_CHANNELS, IMG_WIDTH, IMG_HEIGHT, nb_images, 20, 80)\n",
    "validation_dataset = SquareDataset(IMG_NB_CHANNELS, IMG_WIDTH, IMG_HEIGHT, nb_images, 20, 80)\n",
    "\n",
    "# set training hyperparameters\n",
    "hyperparameters = HyperParameters(\n",
    "    NB_EPOCHS, BATCH_SIZE, LEARNING_RATE, EarlyStoppingParams(3, 0.001)\n",
    ")\n",
    "\n",
    "# run the training process\n",
    "train(\n",
    "    model,\n",
    "    train_dataset,\n",
    "    validation_dataset,\n",
    "    TrainParameters(hyperparameters, INIT_WEIGHTS_PATH, device),\n",
    "    MODEL_PATH,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test the model on a synthetic dataset composed of squares with different colors (1-label problem)\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "from src.benchmark.test import test, TestMetrics, TestReport\n",
    "\n",
    "# build model architecture and load weights generated during the training process\n",
    "model = UNetModel(IMG_NB_CHANNELS, 1, BASE_FM_NUMBER).to(device)\n",
    "model.load_state_dict(torch.load(MODEL_PATH, weights_only=True))\n",
    "\n",
    "# create a test dataset of 10 images\n",
    "nb_images = 10 \n",
    "test_dataset = SquareDataset(IMG_NB_CHANNELS, IMG_WIDTH, IMG_HEIGHT, nb_images, 20, 80)\n",
    "\n",
    "# Configure test report : we are only interested here in micro-averaged accuracy\n",
    "test_report = TestReport(Path(os.getcwd()).joinpath(\"square_dataset_report.json\"),[TestMetrics.ACCURACY])\n",
    "\n",
    "# run evaluation (with segmentation image display activated : verbise = 1)\n",
    "test(device, model, test_dataset, test_report, verbose=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchsemanticsegmentation-py3.12 (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
